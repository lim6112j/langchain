


from langchain_community.llms import Ollama


from langchain_core.prompts import ChatPromptTemplate


from langchain_core.output_parsers import StrOutputParser


from langchain_community.document_loaders import WebBaseLoader


from langchain_community.embeddings import OllamaEmbeddings


from langchain_community.vectorstores import FAISS


from langchain_text_splitters import RecursiveCharacterTextSplitter


from langchain_core.documents import Document


from langchain.chains.combine_documents import create_stuff_documents_chain


url = "https://www.catch.co.kr/News/RecruitNews/251560"


question = "현대 자동차의 디자인 능력에 대해 한글로 말해줘"


loader = WebBaseLoader(url)


docs = loader.load()


text_splitter = RecursiveCharacterTextSplitter()


documents = text_splitter.split_documents(docs)


embeddings = OllamaEmbeddings()


vector = FAISS.from_documents(documents, embeddings)


output_parser = StrOutputParser()


prompt = ChatPromptTemplate.from_template("""Answer the following question based only on the provided context:

<context>
{context}
</context>

Question: {input}""")


llm = Ollama(model="llama2")


document_chain = create_stuff_documents_chain(llm, prompt)


document_chain.invoke({
    "input": question,
    "context": [Document(page_content="langsmith can let you visualize test results")]
})


from langchain.chains import create_retrieval_chain


retriever = vector.as_retriever()


retrieval_chain = create_retrieval_chain(retriever, document_chain)


response = retrieval_chain.invoke({"input": question})


print(response["answer"])



